{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to crawl bio.tools with its API ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows you how to automate the crawling of biotools to filter or transform its content. Please send any comment or feedback to alban.gaignard@univ-nantes.fr. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import json\n",
    "import argparse\n",
    "from argparse import RawTextHelpFormatter\n",
    "from json.decoder import JSONDecodeError\n",
    "import time\n",
    "import sys, os\n",
    "from rdflib import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdfize(json_entry):\n",
    "    \"\"\"\n",
    "    Transforms a biotools json entry into RDF, and returns a JSON-LD serialization. The following fields\n",
    "    are covered: contact, publication, EDAM topic, EDAM operation, EDAM inputs & outputs.\n",
    "    \"\"\"\n",
    "\n",
    "    entry = json_entry\n",
    "\n",
    "    try:\n",
    "\n",
    "        ctx = {\n",
    "            \"@context\": {\n",
    "                \"@base\": \"https://bio.tools/\",\n",
    "                \"biotools\": \"https://bio.tools/ontology/\",\n",
    "                \"edam\": \"http://edamontology.org/\",\n",
    "                \"pubmed\": \"https://www.ncbi.nlm.nih.gov/pubmed/\",\n",
    "                \"pmc\": \"https://www.ncbi.nlm.nih.gov/pmc/\",\n",
    "                \"doi\": \"https://doi.org/\",\n",
    "                \"dc\": \"http://purl.org/dc/terms/\",\n",
    "                \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\",\n",
    "\n",
    "                # \"hasContact\": \"dc:publisher\",\n",
    "                # \"hasPublication\": \"dc:references\",\n",
    "\n",
    "                # \"id\": \"datacite:identifier\",\n",
    "                \"id\": \"dc:identifier\",\n",
    "                # \"name\": \"datacite:title\",\n",
    "                \"name\": \"dc:title\",\n",
    "                # \"description\": \"datacite:description\",\n",
    "                \"description\": \"dc:description\",\n",
    "                # \"license\": \"datacite:rights\",\n",
    "                \"license\": \"dc:license\",\n",
    "                \"hasContact\": \"datacite:contributor\",\n",
    "                \"toolType\": \"datacite:resourceType\",\n",
    "                \"additionDate\": \"datacite:date\",\n",
    "                \"language\": \"datacite:format\",\n",
    "                \"homepage\": \"datacite:alternateIdentifier\",\n",
    "                \"hasPublication\": \"dc:references\",\n",
    "                \"download\": \"datacite:alternateIdentifier\",\n",
    "\n",
    "                \"hasOperation\": \"biotools:has_function\",\n",
    "                \"hasInputData\": \"edam:has_input\",\n",
    "                \"hasOutputData\": \"edam:has_output\",\n",
    "                \"hasTopic\": \"edam:has_topic\"\n",
    "            }\n",
    "        }\n",
    "        entry['@id'] = str(entry['biotoolsID'])\n",
    "        entry['@type'] = {\"@id\": 'biotools:Resource'}\n",
    "        entry.update(ctx)\n",
    "\n",
    "        # for contact in entry['contact']:\n",
    "        #     if not \"hasContact\" in entry.keys():\n",
    "        #         entry['hasContact'] = [contact['name']]\n",
    "        #     else :\n",
    "        #         entry['hasContact'].append(contact['name'])\n",
    "\n",
    "        # for download in entry['download']:\n",
    "        #     if download['url']:\n",
    "        #         if not \"download\" in entry.keys():\n",
    "        #             entry['download'] = [download['url']]\n",
    "        #         else :\n",
    "        #             entry['download'].append(download['url'])\n",
    "\n",
    "        for publication in entry['publication']:\n",
    "            if publication['pmid']:\n",
    "                if not \"hasPublication\" in entry.keys():\n",
    "                    entry['hasPublication'] = [{\"@id\": 'pubmed:' + publication['pmid']}]\n",
    "                else:\n",
    "                    entry['hasPublication'].append({\"@id\": 'pubmed:' + publication['pmid']})\n",
    "            if publication['pmcid']:\n",
    "                if not \"hasPublication\" in entry.keys():\n",
    "                    entry['hasPublication'] = [{\"@id\": 'pmc:' + publication['pmcid']}]\n",
    "                else:\n",
    "                    entry['hasPublication'].append({\"@id\": 'pmc:' + publication['pmcid']})\n",
    "            if publication['doi']:\n",
    "                if not (\"<\" in publication['doi'] or \">\" in publication['doi']):\n",
    "                    if not \"hasPublication\" in entry.keys():\n",
    "                        entry['hasPublication'] = [{\"@id\": \"https://doi.org/\" + publication['doi']}]\n",
    "                    else:\n",
    "                        entry['hasPublication'].append({\"@id\": \"https://doi.org/\" + publication['doi']})\n",
    "\n",
    "        for item in entry['function']:\n",
    "            for op in item['operation']:\n",
    "                if not \"hasOperation\" in entry.keys():\n",
    "                    entry['hasOperation'] = [{\"@id\": op['uri']}]\n",
    "                else:\n",
    "                    entry['hasOperation'].append({\"@id\": op['uri']})\n",
    "\n",
    "            for input in item['input']:\n",
    "                if not \"hasInputData\" in entry.keys():\n",
    "                    entry['hasInputData'] = [{\"@id\": input['data']['uri']}]\n",
    "                else:\n",
    "                    entry['hasInputData'].append({\"@id\": input['data']['uri']})\n",
    "\n",
    "            for output in item['output']:\n",
    "                if not \"hasOutputData\" in entry.keys():\n",
    "                    entry['hasOutputData'] = [{\"@id\": output['data']['uri']}]\n",
    "                else:\n",
    "                    entry['hasOutputData'].append({\"@id\": output['data']['uri']})\n",
    "\n",
    "        for item in entry['topic']:\n",
    "            if not \"hasTopic\" in entry.keys():\n",
    "                entry['hasTopic'] = [{\"@id\": item['uri']}]\n",
    "            else:\n",
    "                entry['hasTopic'].append({\"@id\": item['uri']})\n",
    "\n",
    "    except KeyError as error:\n",
    "        print(json.dumps(entry, indent=4, sort_keys=True))\n",
    "        print()\n",
    "\n",
    "    raw_jld = json.dumps(entry)\n",
    "    return raw_jld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import json\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "def crawl_biotools(keyword, limit=-1):\n",
    "    \"\"\"\n",
    "    Go through all bio.tools entries and print the tool home page if the keyword is found in the tool description.  \n",
    "    :param limit: an integer value specifying the max number of entries to be crawled, -1 by default, means no limit.\n",
    "    \"\"\"\n",
    "    \n",
    "    http = urllib3.PoolManager()\n",
    "    http.headers['Accept'] = 'application/json'\n",
    "    http.headers['Content-type'] = 'application/json'\n",
    "    \n",
    "    try:\n",
    "        req = http.request('GET', 'https://bio.tools/api/tool/?page=1&?format=json')\n",
    "        count_json = json.loads(req.data.decode('utf-8'))\n",
    "        count = int(count_json['count'])\n",
    "        print(str(count)+ \" available BioTools entries\")\n",
    "\n",
    "        i = 1\n",
    "        nb_tools = 1\n",
    "        has_next_page = True\n",
    "        while has_next_page :\n",
    "            req = http.request('GET', 'https://bio.tools/api/tool/?page=' + str(i) + '&?format=json')\n",
    "            try:\n",
    "                entry = json.loads(req.data.decode('utf-8'))\n",
    "            except JSONDecodeError as e:\n",
    "                print(\"Json decode error for \" + str(req.data.decode('utf-8')))\n",
    "                break\n",
    "            has_next_page = (entry['next'] != None)\n",
    "\n",
    "            for tool in entry['list']:\n",
    "                #print(tool)\n",
    "                if keyword in str(tool['description']).lower():\n",
    "                    print(tool['homepage'])\n",
    "                \n",
    "                nb_tools += 1\n",
    "                progress = nb_tools * 100 / count\n",
    "                if (nb_tools % 500 == 0) :\n",
    "                    print(str(round(progress))+\" % done\")\n",
    "                if ((limit != -1) and (nb_tools >= limit)):\n",
    "                    return\n",
    "            i += 1\n",
    "\n",
    "    except urllib3.exceptions.HTTPError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just crawl the first `1000` entries and search for tools with the `rare disease` keyword in their description field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14765 available BioTools entries\n",
      "https://snps-and-go.biocomp.unibo.it/snps-and-go/\n",
      "https://asia.ensembl.org\n",
      "http://github.com/trmznt/vivaxgen-geo\n",
      "https://www.ncbi.nlm.nih.gov/pubmed/?term=31552442\n",
      "https://github.com/vitorpavinato/PypeAmplicon\n",
      "https://github.com/ahvdk/SSNpipe\n",
      "http://www.ncgd.nbri.res.in/PLANET-SNP-Pipeline.aspx\n",
      "https://hirisplex.erasmusmc.nl\n",
      "http://waltzdb.switchlab.org/\n",
      "http://www.bioinfoindia.org/abcd\n",
      "http://hzau.edu.cn/SNP2APA/\n",
      "https://github.com/isglobal-brge/MADloy\n",
      "3 % done\n",
      "http://www.genemed.tech/ascrispr\n",
      "http://www.maizegdb.org\n",
      "http://snp-seek.irri.org/\n",
      "https://dbmdega.shinyapps.io/dbMDEGA/\n",
      "https://www.ncbi.nlm.nih.gov/pubmed/?term=31378650\n",
      "https://www.ncbi.nlm.nih.gov/pubmed/?term=31373606\n",
      "https://pubs.broadinstitute.org/mammals/haploreg/haploreg.php\n",
      "https://github.com/wangying0128/IsomiR_Find\n",
      "http://PHDB.switchlab.org/\n",
      "7 % done\n"
     ]
    }
   ],
   "source": [
    "crawl_biotools(\"snp\", limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
